### Intro
Этот репозиторий содержит решение задачи [California Housing](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjyou-y27-DAxUZ8rsIHem3A5UQFnoECBgQAQ&url=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fcamnugent%2Fcalifornia-housing-prices&usg=AOvVaw3Heommyln5MorynwSU5WOM&opi=89978449).

**Структура проекта**:
```text
│ data/                 # папка с данными (трейн для обучения и семпл для теста/отладки инференса)
│ configs/        
│ models/               # папка с моделями (артефактами) обучения
│   classes/
│   saved_states.dvc    # сохраненные стейты моделей (версионированы через dvc)
│ utils/                # полезные утилиты, используемые в скриптах
```

### Сценарий пользования
1. Использовать репозиторий для работы над моделями.<br>
Это можно сделать через изменение тренировочных данных или существующих моделей и версионирование их через `dvc`.<br>
Для этого в репо уже есть `data/train_data.csv` для обучения модели и примеры сохраненных моделей в `models/saved_states`. Эксперимент также отслеживается через `mlflow`, адрес до которого прокидывается через конфиг `hydra`.
2. Использовать репозиторий для тестирования/отладки инференса.<br>
Для этого уже есть заверсионированный `data/test_data.csv`, на котором пайплайн делает предикты.

### Как потрогать ручками
Основу репозитория составляют два скрипта - `train.py` и `infer.py`.
* `train.py`:
  * Загружает данные с dvc (`train_data.csv`).
  * Обучает пайплайн (препроцессинг/модель/etc), пишет метрики.
  * Сохраняет пайплайн в раздельные файлы с помощью `skops` (см ниже). <br> 
    Название файлов: `repo_name` (`"CH"`) + `artifact_name`. Например, `"CH_model"`.<br>
    Артефакты после обучения автоматические версионируются через `dvc add`, автоматический `dvc push` отключен (команду надо ввести вручную). 

* `infer.py`:
  * Берется модель с dvc - либо обученная модель раннее, либо после `train.py`.
  * Загружается датасет для инференса (`test_data.csv`, также с помощью dvc).
  * Выполняется инференс.
  * Полученный предикт сохраняется в `.csv`.<br>
    Название файла: `repo_name` (`"CH"`) + `"predicts"` (указывается в конфиге) + `timestamp` (UNIX). Например, `"CH_predicts_1704449735"`.<br>
    Файл сохраняется на диск и может быть далее версионирован через `dvc`, загружен в S3 и проч.

Что стоит заметить:
* В название dvc-файлов добавляется название репозитория, эмулируя ситуацию одного ремоута для нескольких проектов.
* `infer.py` можно запустить либо после `train.py`, чтобы сделать сразу тестовый инференс после обучения новой модели, либо отдельно на сохраненной через dvc модели.
* Сериализация выполняется с помощью пакета `skops`, который предназначен для сохранения `sklearn` моделей - более безопасен, чем `pickle`, и хорошо сжимает объекты (см [docs](https://skops.readthedocs.io/en/stable/persistence.html). В целом, если мы пользуемся инструментом внутри компании, то смысла делать 100% ULTRA MAX SAFE LOAD наверное нет, но энивей.